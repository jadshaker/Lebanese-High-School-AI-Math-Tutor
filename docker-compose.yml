services:
  # API Gateway - Main entry point
  gateway:
    build:
      context: services/gateway
      dockerfile: Dockerfile
    container_name: math-tutor-gateway
    ports:
      - '8000:8000'
    env_file:
      - .env
    environment:
      - LARGE_LLM_SERVICE_URL=http://large-llm:8001
      - SMALL_LLM_SERVICE_URL=http://small-llm:8005
      - EMBEDDING_SERVICE_URL=http://embedding:8002
      - CACHE_SERVICE_URL=http://cache:8003
      - FINE_TUNED_MODEL_SERVICE_URL=http://fine-tuned-model:8006
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
    depends_on:
      - large-llm
      - small-llm
      - embedding
      - cache
      - fine-tuned-model
    networks:
      - math-tutor-network

  # Large LLM Service
  large-llm:
    build:
      context: services/large_llm
      dockerfile: Dockerfile
    container_name: math-tutor-large-llm
    ports:
      - '8001:8001'
    env_file:
      - .env
    command: uvicorn src.main:app --host 0.0.0.0 --port 8001 --reload
    networks:
      - math-tutor-network

  # Small LLM Service (Ollama)
  small-llm:
    build:
      context: services/small_llm
      dockerfile: Dockerfile
    container_name: math-tutor-small-llm
    ports:
      - '8005:8005'
    env_file:
      - .env
    environment:
      - SMALL_LLM_SERVICE_URL=http://host.docker.internal:11434
      - SMALL_LLM_MODEL_NAME=${SMALL_LLM_MODEL_NAME:-deepseek-r1:7b}
    command: uvicorn src.main:app --host 0.0.0.0 --port 8005 --reload
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - math-tutor-network

  # Embedding Service
  embedding:
    build:
      context: services/embedding
      dockerfile: Dockerfile
    container_name: math-tutor-embedding
    ports:
      - '8002:8002'
    env_file:
      - .env
    command: uvicorn src.main:app --host 0.0.0.0 --port 8002 --reload
    networks:
      - math-tutor-network

  # Cache Service (Stub)
  cache:
    build:
      context: services/cache
      dockerfile: Dockerfile
    container_name: math-tutor-cache
    ports:
      - '8003:8003'
    env_file:
      - .env
    command: uvicorn src.main:app --host 0.0.0.0 --port 8003 --reload
    networks:
      - math-tutor-network

  # Input Processor Service
  input-processor:
    build:
      context: services/input_processor
      dockerfile: Dockerfile
    container_name: math-tutor-input-processor
    ports:
      - '8004:8004'
    env_file:
      - .env
    command: uvicorn src.main:app --host 0.0.0.0 --port 8004 --reload
    networks:
      - math-tutor-network

  # Fine-Tuned Model Service (Ollama)
  fine-tuned-model:
    build:
      context: services/fine_tuned_model
      dockerfile: Dockerfile
    container_name: math-tutor-fine-tuned-model
    ports:
      - '8006:8006'
    env_file:
      - .env
    environment:
      - FINE_TUNED_MODEL_SERVICE_URL=http://host.docker.internal:11434
      - FINE_TUNED_MODEL_NAME=${FINE_TUNED_MODEL_NAME:-tinyllama:latest}
    command: uvicorn src.main:app --host 0.0.0.0 --port 8006 --reload
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - math-tutor-network

  # Reformulator Service
  reformulator:
    build:
      context: services/reformulator
      dockerfile: Dockerfile
    container_name: math-tutor-reformulator
    ports:
      - '8007:8007'
    env_file:
      - .env
    environment:
      - SMALL_LLM_SERVICE_URL=http://small-llm:8005
    command: uvicorn src.main:app --host 0.0.0.0 --port 8007 --reload
    depends_on:
      - small-llm
    networks:
      - math-tutor-network

  # Answer Retrieval Service (Orchestrator for Phase 2)
  answer-retrieval:
    build:
      context: services/answer_retrieval
      dockerfile: Dockerfile
    container_name: math-tutor-answer-retrieval
    ports:
      - '8008:8008'
    env_file:
      - .env
    environment:
      - EMBEDDING_SERVICE_URL=http://embedding:8002
      - CACHE_SERVICE_URL=http://cache:8003
      - SMALL_LLM_SERVICE_URL=http://small-llm:8005
      - LARGE_LLM_SERVICE_URL=http://large-llm:8001
      - CACHE_TOP_K=${CACHE_TOP_K:-5}
    command: uvicorn src.main:app --host 0.0.0.0 --port 8008 --reload
    depends_on:
      - embedding
      - cache
      - small-llm
      - large-llm
    networks:
      - math-tutor-network

  # Data Processing Service (Orchestrator for Phase 1)
  data-processing:
    build:
      context: services/data_processing
      dockerfile: Dockerfile
    container_name: math-tutor-data-processing
    ports:
      - '8009:8009'
    env_file:
      - .env
    environment:
      - INPUT_PROCESSOR_SERVICE_URL=http://input-processor:8004
      - REFORMULATOR_SERVICE_URL=http://reformulator:8007
    command: uvicorn src.main:app --host 0.0.0.0 --port 8009 --reload
    depends_on:
      - input-processor
      - reformulator
    networks:
      - math-tutor-network

networks:
  math-tutor-network:
    driver: bridge
