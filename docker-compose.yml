services:
  # API Gateway - Main entry point
  gateway:
    build:
      context: services/gateway
      dockerfile: Dockerfile
    container_name: math-tutor-gateway
    ports:
      - '8000:8000'
    env_file:
      - .env
    environment:
      - LARGE_LLM_SERVICE_URL=http://large-llm:8001
      - SMALL_LLM_SERVICE_URL=http://small-llm:8005
      - EMBEDDING_SERVICE_URL=http://embedding:8002
      - REFORMULATOR_SERVICE_URL=http://reformulator:8009
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
    depends_on:
      - large-llm
      - small-llm
      - embedding
      - reformulator
    networks:
      - math-tutor-network

  # Large LLM Service
  large-llm:
    build:
      context: services/large_llm
      dockerfile: Dockerfile
    container_name: math-tutor-large-llm
    ports:
      - '8001:8001'
    env_file:
      - .env
    command: uvicorn src.main:app --host 0.0.0.0 --port 8001 --reload
    networks:
      - math-tutor-network

  # Small LLM Service (Ollama)
  small-llm:
    build:
      context: services/small_llm
      dockerfile: Dockerfile
    container_name: math-tutor-small-llm
    ports:
      - '8005:8005'
    env_file:
      - .env
    environment:
      - OLLAMA_SERVICE_URL=http://host.docker.internal:11434
      - OLLAMA_MODEL_NAME=${OLLAMA_MODEL_NAME:-deepseek-r1:7b}
    command: uvicorn src.main:app --host 0.0.0.0 --port 8005 --reload
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - math-tutor-network

  # Embedding Service
  embedding:
    build:
      context: services/embedding
      dockerfile: Dockerfile
    container_name: math-tutor-embedding
    ports:
      - '8002:8002'
    env_file:
      - .env
    command: uvicorn src.main:app --host 0.0.0.0 --port 8002 --reload
    networks:
      - math-tutor-network

  # Reformulator Service
  reformulator:
    build:
      context: services/reformulator
      dockerfile: Dockerfile
    container_name: math-tutor-reformulator
    ports:
      - '8009:8009'
    env_file:
      - .env
    environment:
      - OLLAMA_SERVICE_URL=http://host.docker.internal:11434
      - OLLAMA_MODEL_NAME=${OLLAMA_MODEL_NAME:-deepseek-r1:7b}
    command: uvicorn src.main:app --host 0.0.0.0 --port 8009 --reload
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - math-tutor-network

networks:
  math-tutor-network:
    driver: bridge
